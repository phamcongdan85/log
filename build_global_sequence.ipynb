{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceType":"datasetVersion","sourceId":14669917,"datasetId":9364016,"databundleVersionId":15512064}],"dockerImageVersionId":31259,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-30T03:00:14.275975Z","iopub.execute_input":"2026-01-30T03:00:14.276356Z","iopub.status.idle":"2026-01-30T03:00:14.290952Z","shell.execute_reply.started":"2026-01-30T03:00:14.276322Z","shell.execute_reply":"2026-01-30T03:00:14.289818Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hdfs-2k/HDFS_2k.log\n/kaggle/input/hdfs-2k/hdfs_log_templates.json\n/kaggle/input/hdfs-2k/HDFS_2k.log_structured.csv\n/kaggle/input/hdfs-2k/HDFS_2k.log_templates.csv\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"import pandas as pd\nimport json\n\nSTRUCTURED_LOG = \"/kaggle/input/hdfs-2k/HDFS_2k.log_structured.csv\"\nMAPPING_FILE = \"/kaggle/input/hdfs-2k/hdfs_log_templates.json\"\nOUT_DIR = \"/kaggle/working/data/output\"\n\ndef build_global_sequence():\n    df = pd.read_csv(\n        STRUCTURED_LOG,\n        dtype={\"Date\": str, \"Time\": str}\n    )\n\n    with open(MAPPING_FILE) as f:\n        mapping = json.load(f)\n\n    df[\"log_key\"] = df[\"EventId\"].apply(lambda x: mapping.get(x, -1))\n\n    global_df = pd.DataFrame({\n        \"raw_idx\": df.index,\n        \"timestamp\": pd.to_datetime(\n            df[\"Date\"] + df[\"Time\"],\n            format=\"%y%m%d%H%M%S\"\n        ),\n        \"log_key\": df[\"log_key\"],\n        \"content\": df[\"Content\"]\n    })\n\n    global_df = global_df.sort_values(\"timestamp\").reset_index(drop=True)\n    return global_df\n\nif __name__ == \"__main__\":\n    g = build_global_sequence()\n    print(\"ok chua????\")\n    os.makedirs(OUT_DIR, exist_ok=True)\n    g.to_csv(\"data/output/global_sequence.csv\", index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-30T03:00:14.292785Z","iopub.execute_input":"2026-01-30T03:00:14.293159Z","iopub.status.idle":"2026-01-30T03:00:14.345408Z","shell.execute_reply.started":"2026-01-30T03:00:14.293118Z","shell.execute_reply":"2026-01-30T03:00:14.344536Z"}},"outputs":[{"name":"stdout","text":"ok chua????\n","output_type":"stream"}],"execution_count":12}]}